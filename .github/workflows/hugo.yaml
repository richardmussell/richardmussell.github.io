name: Deploy Hugo site to Pages

on:
  push:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

defaults:
  run:
    shell: bash

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      HUGO_VERSION: 0.152.2
    steps:
      - name: Checkout
        uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1
        with:
          submodules: true
          fetch-depth: 0

      - name: Setup Pages
        id: pages
        uses: actions/configure-pages@983d7736d9b0ae728b81ab479565c72886d7745b # v5

      - name: Install Hugo
        uses: peaceiris/actions-hugo@75d2e84710de30f6ff7268e08f310b60ef14033f # v3
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true

      - name: Scrub Image Metadata (Privacy-by-Design)
        run: |
          python3 -m pip install --upgrade pip
          pip install Pillow
          python3 << 'EOF'
          import os
          import sys
          from pathlib import Path
          from PIL import Image
          
          def scrub_image_metadata(image_path):
              try:
                  img = Image.open(image_path)
                  original_format = img.format
                  data = list(img.getdata())
                  image_without_exif = Image.new(img.mode, img.size)
                  image_without_exif.putdata(data)
                  
                  if original_format == 'JPEG':
                      image_without_exif.save(image_path, 'JPEG', quality=95, optimize=True)
                  elif original_format == 'PNG':
                      image_without_exif.save(image_path, 'PNG', optimize=True)
                  else:
                      image_without_exif.save(image_path, format=original_format)
                  
                  img.close()
                  image_without_exif.close()
                  return True
              except Exception as e:
                  print(f"  âŒ Error processing {image_path}: {str(e)}", file=sys.stderr)
                  return False
          
          def find_images(directories):
              image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}
              images = []
              for directory in directories:
                  dir_path = Path(directory)
                  if not dir_path.exists():
                      continue
                  for ext in image_extensions:
                      images.extend(dir_path.rglob(f'*{ext}'))
              return images
          
          directories_to_scan = ['static', 'themes/mussell-portfolio/assets', 'themes/mussell-portfolio/static']
          images = find_images(directories_to_scan)
          
          if images:
              print(f"ðŸ”’ Scrubbing metadata from {len(images)} image(s)...")
              success_count = sum(1 for img in images if scrub_image_metadata(img))
              print(f"âœ… Successfully scrubbed {success_count}/{len(images)} images")
          else:
              print("âœ… No images found to process")
          EOF

      - name: Build with Hugo
        env:
          HUGO_ENV: production
        run: |
          hugo \
            --gc \
            --minify \
            --baseURL "${{ steps.pages.outputs.base_url }}/"

      - name: Verify SRI Generation
        run: |
          echo "ðŸ” Checking for any valid SRI integrity attributes..."
          # Use -q (quiet) and -r (recursive) to check for the string. 
          # This avoids 'Broken pipe' errors by not outputting to a stream.
          if grep -qr "integrity=\"sha" public/; then
            echo "âœ… SRI hashes verified. Fortress-grade security confirmed."
          else
            echo "âŒ ERROR: No SRI hashes found in built HTML. Security check failed."
            exit 1
          fi

      - name: Start Local Server (Linkinator & Lighthouse)
        run: |
          cd public
          python3 -m http.server 1313 > /dev/null 2>&1 &
          echo $! > /tmp/server.pid
          sleep 5
          echo "âœ… Local server started on port 1313 for link checking and Lighthouse"

      - name: Linkinator (Broken Link & Accessibility Guard)
        run: |
          # Check links against local server to avoid false 404s from undeployed GitHub Pages URLs
          # Skip production domain and external domains we don't control
          npx linkinator http://localhost:1313 --recurse --silent --skip "https://richardmussell\.github\.io/.*" --skip "https://formspree\.io/.*" || (echo "âŒ Broken links detected" && exit 1)
          echo "âœ… All links and assets verified."

      - name: Lighthouse CI (Performance Guard)
        run: |
          export LHCI_BASE_URL="http://localhost:1313"
          # npx handles downloading and executing without path issues
          npx @lhci/cli@0.12.x autorun --config=./.lighthouserc.js || (pkill -f "python3 -m http.server" && echo "âŒ Lighthouse failed" && exit 1)
          echo "âœ… Lighthouse passed."

      - name: Stop Local Server
        if: always()
        run: |
          if [ -f /tmp/server.pid ]; then
            kill $(cat /tmp/server.pid) 2>/dev/null || true
            pkill -f "python3 -m http.server" || true
          fi

      - name: Upload artifact
        uses: actions/upload-pages-artifact@56afc609e74202658d3ffba0e8f6dda462b719fa # v3
        with:
          path: ./public

  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@d6db90164ac5ed86f2b6aed7e0febac5b3c0c03e # v4
